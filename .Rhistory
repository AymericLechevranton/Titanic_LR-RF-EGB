detection_outliers <- function(x) {
a <- boxplot(x)$out
b <- subset(x, !(x %in%a))
par(mfrow=c(2, 3))#ncol(x)
#ligne 1
boxplot(x, main = 'Box plot avec outliers')
hist(x, breaks = 8, main = 'Histogramme données \n cent/réd avec outliers', freq = F)
densite1 <- density(log(x))
lines(densite1, col = 'red', lwd=3)
#ligne 2
if (length(a) > 0) {
boxplot(x, outline = F, main = 'Box plot sans outlier')
hist(b, breaks = 8, main = 'Histogramme sans outlier', freq=F )
densite1 <- density(b)
lines(densite1, col = 'red', lwd = 3)
hist(log(b), freq = F, breaks = 8, col = 'cyan', main = 'Histogramme du log \nsans outlier')
densite <- density(log(b))
lines(densite, col = "red",lwd=3)
}
}
detection_outliers(eaux2018_fr1$Ca)
detection_outliers(eaux2018_fr1$Mg)
detection_outliers(eaux2018_fr1$Na)
detection_outliers <- function(x) {
a <- boxplot(x)$out
b <- subset(x, !(x %in%a))
par(mfrow=c(2, 3))#ncol(x)
#ligne 1
boxplot(x, main = 'Box plot avec outliers')
hist(scale(x), breaks = 8, main = 'Histogramme données \n cent/réd avec outliers', freq = F)
densite1 <- density(log(x))
lines(densite1, col = 'red', lwd=3)
#ligne 2
if (length(a) > 0) {
boxplot(x, outline = F, main = 'Box plot sans outlier')
hist(b, breaks = 8, main = 'Histogramme sans outlier', freq=F )
densite1 <- density(b)
lines(densite1, col = 'red', lwd = 3)
hist(log(b), freq = F, breaks = 8, col = 'cyan', main = 'Histogramme du log \nsans outlier')
densite <- density(log(b))
lines(densite, col = "red",lwd=3)
}
}
detection_outliers(eaux2018_fr1$Ca)
detection_outliers(eaux2018_fr1$Mg)
detection_outliers(eaux2018_fr1$Na)
detection_outliers(eaux2018_fr1$Ca)
detection_outliers(eaux2018_fr1$Mg)
detection_outliers(eaux2018_fr1$Na)
detection_outliers(eaux2018_fr1$Cl)
detection_outliers(eaux2018_fr1$SO4)
detection_outliers(na.omit(eaux2018_fr1$HCO3))
detection_outliers(na.omit(eaux2018_fr1$Cl))
detection_outliers(eaux2018_fr1$SO4)
detection_outliers(na.omit(eaux2018_fr1$HCO3))
detection_outliers(na.omit(eaux2018_fr1$PH))
detection_outliers(na.omit(eaux2018_fr1$PH))
detection_outliers(na.omit(eaux2018_fr1$NO3))
#données imputées
impute_acp <- acp_fonction(dat)
library(FactoMineR);library(factoextra);library(tidyverse);library(MASS);library(car)
# Créez une variable continue aléatoire de longueur 23,
# Même longeur que le nombre d'individus actifs dans l'ACP
set.seed (123)
my.cont.var <- rnorm(84)
# Colorer les individus par la variable continue
fviz_pca_ind(eaux_PCA, col.ind = my.cont.var,
gradient.cols = c("blue", "yellow", "red"),
legend.title = "Cont.Var")
#Colorer les groupes
# La variable Species (index = 5) est supprimée
# avant l'ACP
iris.pca <- PCA(eaux_active, graph = FALSE)
fviz_pca_ind(iris.pca,
geom.ind = "point", # Montre les points seulement (mais pas le "text")
col.ind = eaux2018_fr1$Nature, # colorer by groups
palette = c("#00AFBB", "#E7B800", "#FC4E07"),
addEllipses = TRUE, # Ellipses de concentration
legend.title = "Groups"
)
#Optionnel:
# Afficher les points et l'annotation des variables
fviz_pca_var(eaux_PCA, geom.var = c("point", "text"))
# Afficher uniquement l'annotation des individus
fviz_pca_ind(eaux_PCA, geom.ind = "text")
#Centre de gravité:
fviz_pca_ind (iris.pca,
geom.ind = "point", # afficher les points seulement (pas de "texte")
col.ind = eaux2018_fr1$Nature, # Couleur par groupes
legend.title = "Groupes",
mean.point = FALSE)
#Colorer les groupes
# La variable Species (index = 5) est supprimée
# avant l'ACP
iris.pca <- PCA(eaux_active, graph = FALSE)
fviz_pca_ind(iris.pca,
geom.ind = "point", # Montre les points seulement
col.ind = eaux2018_fr1$Nature,
palette = c("#00AFBB", "#E7B800", "#FC4E07"),
addEllipses = TRUE, # Ellipses de concentration
legend.title = "Groups"
)
#Paramètres graphiques
ind.p <- fviz_pca_ind(iris.pca, geom = "point", col.ind = eaux2018_fr1$Nature)
ggpubr::ggpar(ind.p,
title = "Principal component Analysis",
subtitle = "Eaux data set",
caption = "Source: factoextra",
xlab = "PC1", ylab = "PC2",
legend.title = "Nature", legend.position = "top",
ggtheme = theme_gray(), palette = "jco"
)
#Biplot des individus:
fviz_pca_biplot(eaux_PCA, repel = TRUE,
col.var = "#2E9FDF", # Couleur des variables
col.ind = "#696969"  # Couleur des individues
)
fviz_pca_biplot(iris.pca,
# Individus
geom.ind = "point",
fill.ind = eaux2018_fr1$Nature, col.ind = "black",
pointshape = 21, pointsize = 2,
palette = "jco",
addEllipses = TRUE,
# Variables
alpha.var ="contrib", col.var = "contrib",
gradient.cols = "RdYlBu",
legend.title = list(fill = "Species", color = "Contrib",
alpha = "Contrib")
)
#Biplot des individus:
fviz_pca_biplot(eaux_PCA, repel = TRUE,
col.var = "#2E9FDF", # Couleur des variables
col.ind = "#696969"  # Couleur des individues
)
#Biplot des individus:
fviz_pca_biplot(iris.pca,
# Individus
geom.ind = "point",
fill.ind = eaux2018_fr1$Nature, col.ind = "black",
pointshape = 21, pointsize = 2,
palette = "jco",
addEllipses = TRUE,
# Variables
alpha.var ="contrib", col.var = "contrib",
gradient.cols = "RdYlBu",
legend.title = list(fill = "Species", color = "Contrib",
alpha = "Contrib")
)
#Colorer les groupes
# La variable Species (index = 5) est supprimée
# avant l'ACP
iris.pca <- PCA(eaux_active, graph = FALSE)
fviz_pca_ind(iris.pca,
geom.ind = "point", # Montre les points seulement
col.ind = eaux2018_fr1$Nature,
palette = c("#00AFBB", "#E7B800", "#FC4E07"),
addEllipses = TRUE, # Ellipses de concentration
legend.title = "Groups"
)
#Graphique des individus:
fviz_pca_ind (eaux_PCA)
#coloré en fonction de leur cos2:
fviz_pca_ind (eaux_PCA, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
#bar plot de la qualité de représentation (cos2) des individus:
fviz_cos2(eaux_PCA, choice = "ind")
# Contribution totale sur PC1 et PC2:
fviz_contrib(eaux_PCA, choice = "ind", axes = 1:2)
#Ce graphique est un des graphiques qui n'a pas été utilisés
#mais il permet de regrouper en 3 groupes (conformément aux cercles que nous avons pu voir précédement)
#les variables sur le cercle de corrélation par la méthode kmeans (ici k=3).
# Colorer les variables par groupes
set.seed(123)
res.km <- kmeans(var$coord, centers = 3, nstart = 25)
grp <- as.factor(res.km$cluster)
fviz_pca_var(eaux_PCA, col.var = grp,
palette = c("#0073C2FF", "#EFC000FF", "#868686FF"),
legend.title = "Cluster")
#La contribution des variables aux axes principaux
head(var$contrib, 4)
#Plus la valeur de la contribution est importante, plus la variable contribue à la composante principale en question.
corrplot(var$contrib, is.corr=FALSE)
# Contributions des variables à PC1
fviz_contrib(eaux_PCA, choice = "var", axes = 1, top = 10)
# Contributions des variables à PC2
fviz_contrib(eaux_PCA, choice = "var", axes = 2, top = 10)
#Les variables les plus importantes (ou, contributives) peuvent être mises en évidence sur le graphe de corrélation:
fviz_pca_var(eaux_PCA, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)
# Colorer en fonction du cos2: qualité de représentation
fviz_pca_var(eaux_PCA, col.var = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Évite le chevauchement de texte
)
#Pour visualiser le cos2 des variables sur toutes les dimensions:
corrplot(var$cos2, is.corr=FALSE)
#Qualité de représentation
#La qualité de représentation sur la carte de l'ACP s'appelle cos2:
head(var$cos2, 4)
#Pour visualiser les variables:
fviz_pca_var(eaux_PCA, col.var = "black")
#Graphique des valeurs propres:
fviz_eig(eaux_PCA, addlabels = TRUE, ylim = c(0, 50),
ylab="Pourcentage de variance expliqué",
main='')
#Graphique des valeurs propres:
fviz_eig(eaux_PCA, addlabels = TRUE, ylim = c(0, 50),
ylab="Pourcentage de variance expliqué",
main='')
eaux2018 <- data.frame(read_delim("C:/Users/Aymeric/Documents/#M1 - Université/M1-S1_-_Analyse de données/Projet/Eaux2018.txt",
"\t", escape_double = FALSE, trim_ws = TRUE))
head(eaux2018)
eaux2018$Nature <- ifelse(eaux2018$Nature=='gaz', 1, 0)
eaux2018_fr <- eaux2018[eaux2018$Pays=='France',]
eaux2018_mar <- eaux2018[eaux2018$Pays=='Maroc',]
head(eaux2018_fr)
head(eaux2018_fr)
data<-log(na.omit(eaux2018_fr[,2:11])+1)
head(data)
#Déterminer le numéro de bloc de chaque individu
n<-nrow(data) #nombre d'observations
k<-10 #pour 10-validation croisée
taille<-n%/%k #déterminer la taille de chaque bloc
set.seed(5) #pour obtenir la même séquence tout le temps
alea<-runif(n) #générer une colonne de valeurs aléatoires
rang<-rank(alea) #associer un individu à chaque rang
bloc<-(rang-1)%/%taille +1 #associer chaque individu à un numéro de bloc
bloc<-factor(bloc) #transformer en factor
print(summary(bloc)) #impression de contrôle
#Lancer la validation croisée pour Nature
all.err<-matrix(0,ncol=ncol(data),nrow=k)
for (j in 1:ncol(data)){
xnam <- names(data)
fmla <- as.formula(paste(paste(xnam[j]," ~ "), paste(xnam[-j], collapse= "+")))
for (i in 1:k){
#apprendre le modèle à tous les individus sauf le blocs i
arbre<-rpart(fmla, data=data[bloc!=i,], method='class')
#appliquer le modèle sur le bloc i
pred<-predict(arbre,newdata=data[bloc==i,], type='class')
#matrice de confusion
mc<-table(data[bloc==i,j],pred)
#taux d'erreur
errare<-0
for (p in 1:(dim(mc)[1])){
for (q in 1:(dim(mc)[2])){
if (rownames(mc)[p]==colnames(mc)[q]){errare<-errare+mc[p,q]}
}
}
#conserver
err<-1.0-errare/sum(mc)
all.err[i,j]<-err
}}
library(stats);library(e1071);library(missMDA);library(corrplot);library(rpart)
for (i in 1:k){
#apprendre le modèle à tous les individus sauf le blocs i
arbre<-rpart(fmla, data=data[bloc!=i,], method='class')
#appliquer le modèle sur le bloc i
pred<-predict(arbre,newdata=data[bloc==i,], type='class')
#matrice de confusion
mc<-table(data[bloc==i,j],pred)
#taux d'erreur
errare<-0
for (p in 1:(dim(mc)[1])){
for (q in 1:(dim(mc)[2])){
if (rownames(mc)[p]==colnames(mc)[q]){errare<-errare+mc[p,q]}
}
}
#conserver
err<-1.0-errare/sum(mc)
all.err[i,j]<-err
}}
for (j in 1:ncol(data)){
xnam <- names(data)
fmla <- as.formula(paste(paste(xnam[j]," ~ "), paste(xnam[-j], collapse= "+")))
for (i in 1:k){
#apprendre le modèle à tous les individus sauf le blocs i
arbre<-rpart(fmla, data=data[bloc!=i,], method='class')
#appliquer le modèle sur le bloc i
pred<-predict(arbre,newdata=data[bloc==i,], type='class')
#matrice de confusion
mc<-table(data[bloc==i,j],pred)
#taux d'erreur
errare<-0
for (p in 1:(dim(mc)[1])){
for (q in 1:(dim(mc)[2])){
if (rownames(mc)[p]==colnames(mc)[q]){errare<-errare+mc[p,q]}
}
}
#conserver
err<-1.0-errare/sum(mc)
all.err[i,j]<-err
}}
#vecteur des erreurs recueillies
print(all.err)
#erreur en validation croisée
#on peut se contenter d'une moyenne non pondérée puisque les blocs sont de taille identique
err.cv<-colMeans(all.err)
print(err.cv)
library(randomForest)
library(tidyverse)
educ <- read.csv2("https:\\data.education.gouv.fr\explore\dataset\fr-en-effectifs-des-personnels-des-ecoles-et-etablissements-du-2nd-degre\download\?format=csv&timezone=Europe\Berlin&use_labels_for_header=true")
library(tidyverse)
educ <- read.csv2("https://data.education.gouv.fr/explore/dataset/fr-en-effectifs-des-personnels-des-ecoles-et-etablissements-du-2nd-degre/download/?format=csv&timezone=Europe/Berlin&use_labels_for_header=true")
educ <- read.csv2("https://data.education.gouv.fr/explore/dataset/fr-en-effectifs-des-personnels-des-ecoles-et-etablissements-du-2nd-degre/download/?format=csv&timezone=Europe/Berlin&use_labels_for_header=true")
library("FactoMineR")
library("factoextra")
library("Amelia")
library("VIM")
data0 <- read.csv(file="train.csv",
quote= "\"", dec = ".", header = TRUE)
data<-data0[,c(1,2,3,5,6,7,8,10,12,12)]
head(data)
#Mettre les variables qualitatives sous forme binaire
data$Sex<-ifelse(data$Sex=="male", yes = 1, no = 0)
data$Embarked<-ifelse(data$Embarked=="S", yes = 1, no = 0)
data$Embarked.S<-data$Embarked
data$Embarked.1<-ifelse(data$Embarked.1=="C", yes = 1, no = 0)
data$Embarked.C<-data$Embarked.1
data<-data[,-c(9,10)]
head(data)
dat<-cbind(data[,1:2],scale(data[,3:10]))
head(dat)
data0 <- read.csv(file="train.csv",
quote= "\"", dec = ".", header = TRUE)
setwd("~/EDX - MOOC/#Kaggle/TitanicLogistic")
data0 <- read.csv(file="train.csv",
quote= "\"", dec = ".", header = TRUE)
data<-data0[,c(1,2,3,5,6,7,8,10,12,12)]
head(data)
#Mettre les variables qualitatives sous forme binaire
data$Sex<-ifelse(data$Sex=="male", yes = 1, no = 0)
data$Embarked<-ifelse(data$Embarked=="S", yes = 1, no = 0)
data$Embarked.S<-data$Embarked
data$Embarked.1<-ifelse(data$Embarked.1=="C", yes = 1, no = 0)
data$Embarked.C<-data$Embarked.1
data<-data[,-c(9,10)]
head(data)
dat<-cbind(data[,1:2],scale(data[,3:10]))
head(dat)
#ou Utilisation des données complètes
dat.NA<-na.omit(dat)
write.csv(dat.NA,file='trainNA.csv',row.names=F)
data0 <- read.csv(file="test.csv",
quote= "\"", dec = ".", header = TRUE)
data<-data0[,c(1,2,4,5,6,7,9,11,11)]
head(data)
#Mettre les variables qualitatives sous forme binaire
data$Sex<-ifelse(data$Sex=="male", yes = 1, no = 0)
data$Embarked<-ifelse(data$Embarked=="S", yes = 1, no = 0)
data$Embarked.S<-data$Embarked
data$Embarked.1<-ifelse(data$Embarked.1=="C", yes = 1, no = 0)
data$Embarked.C<-data$Embarked.1
data<-data[,-c(8,9)]
head(data)
dat<-cbind(data[,1],scale(data[,2:9]))
head(dat)
#ou Utilisation des données complètes
dat.NA<-na.omit(dat)
write.csv(dat.NA,file='testNA.csv',row.names=F)
dat.NA<-round(dat.NA,digits=3)
head(dat.NA)
dat.NA <- data.frame(dat.NA)
colnames(dat.NA)[1]<-'PassengerId'
write.csv(dat.NA,file='testNA.csv',row.names=F)
colnames(dat.NA)
write.csv(dat.NA,file='testNA.csv',row.names=F)
write.csv(dat.NA,file='testNA.csv',row.names=F)
data0 <- read.csv(file="train.csv",
quote= "\"", dec = ".", header = TRUE)
data<-data0[,c(1,2,3,5,6,7,8,10,12,12)]
head(data)
#Mettre les variables qualitatives sous forme binaire
data$Sex<-ifelse(data$Sex=="male", yes = 1, no = 0)
data$Embarked<-ifelse(data$Embarked=="S", yes = 1, no = 0)
data$Embarked.S<-data$Embarked
data$Embarked.1<-ifelse(data$Embarked.1=="C", yes = 1, no = 0)
data$Embarked.C<-data$Embarked.1
data<-data[,-c(9,10)]
dat<-cbind(data[,1:2],scale(data[,3:10]))
head(data)
head(dat)
#ou Utilisation des données complètes
dat.NA<-na.omit(dat)
dat.NA<-round(dat.NA,digits=3)
head(dat.NA)
dat.NA <- data.frame(dat.NA)
colnames(dat.NA)[1]<-'PassengerId'
colnames(dat.NA)[2]<-'Survived'
write.csv(dat.NA,file='trainNA.csv',row.names=F)
install.packages("xgboost")
#Utilisation de XGBoost
library("xgboost")
?require
NA_train <- read.csv('trainNA.csv')
NA_test <- read.csv('testNA.csv')
xgb1 <- xgboost(data = NA_train, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
NA_train<-matrix(NA_train)
xgb1 <- xgboost(data = NA_train, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
install.packages("Matrix")
NA_train<-dgCMatrix(NA_train)
NA_train <- read.csv('trainNA.csv')
NA_test <- read.csv('testNA.csv')
str(NA_train)
NA_train<-matrix(NA_train)
str(NA_train)
View(NA_train)
NA_train <- read.csv('trainNA.csv')
NA_train<-sparseMatrix(NA_train)
NA_train<-Matrix(NA_train)
NA_train<-sparsematrix(NA_train)
library("Matrix")
NA_train<-sparseMatrix(NA_train)
NA_train<-Matrix(NA_train)
NA_train <- read.csv('trainNA.csv')
NA_train<-Matrix(NA_train)
NA_train<-matrix(NA_train, ncol=10)
NA_train <- as(NA_train, "dgCMatrix")
View(NA_train)
View(geneExpression)
xgb1 <- xgboost(data = NA_train[,3:10], label=Na_train$Survived, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
#Utilisation de XGBoost
library("xgboost")
xgb1 <- xgboost(data = NA_train[,3:10], label=Na_train$Survived, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
NA_train <- read.csv('trainNA.csv')
xgb1 <- xgboost(data = NA_train[,3:10], label=Na_train$Survived, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
xgb1 <- xgboost(data = NA_train[,3:10], label=NA_train$Survived, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
NA_train<-matrix(NA_train, ncol=10)
xgb1 <- xgboost(data = NA_train[,3:10], label=NA_train$Survived, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
NA_train<-matrix(NA_train[,3:10], ncol=10)
NA_train <- read.csv('trainNA.csv')
NA_train<-matrix(NA_train[,3:10], ncol=10)
NA_train <- read.csv('trainNA.csv')
#Utilisation de XGBoost
library("xgboost")
library("Matrix")
NA_train<-matrix(NA_train[,3:10], ncol=10)
NA_train <- read.csv('trainNA.csv')[,3:10]
NA_train <- read.csv('trainNA.csv')
NA_train<-matrix(NA_train[,3:10])
xgb1 <- xgboost(data = NA_train, label=NA_train$Survived, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
xgb1 <- xgboost(data = NA_train, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
View(NA_train)
?matrix
NA_train <- read.csv('trainNA.csv')
NA_train<-as.matrix(NA_train[,3:10])
View(NA_train)
xgb1 <- xgboost(data = NA_train, label=NA_train$Survived, max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
View(NA_train)
xgb1 <- xgboost(data = NA_train, label=NA_train[,2], max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
NA_train0 <- read.csv('trainNA.csv')
NA_train<-as.matrix(NA_train0[,3:10])
xgb1 <- xgboost(data = NA_train, label=NA_train0[,2], max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
NA_train <- as(NA_train, "dgCMatrix")
xgb1 <- xgboost(data = NA_train, label=NA_train0[,2], max.depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = "binary:logistic")
View(NA_train)
View(NA_train)
NA_test0 <- read.csv('testNA.csv')
NA_test <- as.matrix(NA_test0)
NA_test <- as(NA_test, "dgCMatrix")
pred <- predict(xgb1, NA_test)
pred <- predict(xgb1, NA_test[,2:9])
survived.pred <- cbind(NA_test[,1],data.frame(round(pred)))
View(survived.pred)
colnames(survived.pred) <- c('PassengerId','Survived')
View(survived.pred)
write.csv(survived.pred, file="result.csv", quote=F, row.names=FALSE)
View(survived.pred)
NA_test0 <- read.csv('test01.csv')
NA_test <- as.matrix(NA_test0)
NA_test <- as(NA_test, "dgCMatrix")
pred <- predict(xgb1, NA_test[,2:9])
survived.pred <- cbind(NA_test[,1],data.frame(round(pred)))
colnames(survived.pred) <- c('PassengerId','Survived')
write.csv(survived.pred, file="result.csv", quote=F, row.names=FALSE)
#ou Création d'un modèle de forêt aléatoire
library(randomForest)
?randomForest
rndfor <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked.S + Embarked.C,
data = data_train, na.action = na.roughfix)
#Importation des données (avec imputation kNN)
data_train <- read.csv('train01.csv')
data_test <- read.csv('test01.csv')
rndfor <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked.S + Embarked.C,
data = data_train, na.action = na.roughfix)
rndfor
print(rndfor)
plot(rndfor$err.rate[, 1], type = "l", xlab = "nombre d'arbres", ylab = "erreur OOB")
View(data_train)
rndfor$err.rate
rndfor <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked.S + Embarked.C,
ntree=5000,
data = data_train, na.action = na.roughfix)
rndfor
rndfor <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked.S + Embarked.C,
ntree=5000, mty=4,
data = data_train, na.action = na.roughfix)
rndfor
rndfor <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked.S + Embarked.C,
ntree=5000, mty=1,
data = data_train, na.action = na.roughfix)
rndfor
#0.1281 et 45.84
#0.1268 et 46.36
#0.1267 et 46.42
survived.pred <- predict(rndfor, type = "response", newdata = data_test)
head(survived.pred)
survived.pred <- cbind(data_test[,1],data.frame(round(survived.pred)))
colnames(survived.pred) <- c('PassengerId','Survived')
write.csv(survived.pred, file="result.csv", quote=F, row.names=FALSE)
